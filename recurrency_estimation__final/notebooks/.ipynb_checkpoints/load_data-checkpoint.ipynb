{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/loidolt/RowlandEtAl/popping-off/popoff/popoff/loadpaths.py\n",
      "/home/loidolt/RowlandEtAl/Vape\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "import xarray as xr\n",
    "\n",
    "sys.path.append(\"../../RowlandEtAl/popping-off/popoff/popoff/\")\n",
    "sys.path.append(\"../../RowlandEtAl/popping-off/popoff/\")\n",
    "sys.path.append(\"../../RowlandEtAl/popping-off/scripts/\")\n",
    "\n",
    "sys.path.append(\"../../RowlandEtAl/Vape/utils/\")\n",
    "sys.path.append(\"../../RowlandEtAl/Vape/\")\n",
    "\n",
    "import popoff\n",
    "#import pop_off_functions as pof\n",
    "#import pop_off_plotting as pop\n",
    "from popoff import loadpaths\n",
    "from Session import SessionLite\n",
    "from linear_model import PoolAcrossSessions, LinearModel, MultiSessionModel\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long post time\n",
      "long post time\n",
      "long post time\n",
      "long post time\n",
      "long post time\n",
      "Mouse RL070, run 29  registered no-lick hit. changed to too soon\n",
      "long post time\n",
      "long post time\n",
      "Mouse RL117, run 29  registered no-lick hit. changed to too soon\n",
      "Mouse RL117, run 29  registered no-lick hit. changed to too soon\n",
      "long post time\n",
      "long post time\n",
      "long post time\n",
      "Mouse RL116, run 32  registered no-lick hit. changed to too soon\n",
      "Mouse RL116, run 32  registered no-lick hit. changed to too soon\n",
      "Mouse RL116, run 32  registered no-lick hit. changed to too soon\n",
      "long post time\n",
      "ALERT SESSIONS NOT SUBSAMPLED\n",
      "long post time\n",
      "long post time\n",
      "long post time\n",
      "long post time\n",
      "long post time\n",
      "long post time\n",
      "long post time\n",
      "long post time\n",
      "long post time\n",
      "long post time\n",
      "long post time\n",
      "{0: instance Mouse J064, run 10 of Session class, 1: instance Mouse J064, run 11 of Session class, 2: instance Mouse J064, run 14 of Session class, 3: instance Mouse RL070, run 28 of Session class, 4: instance Mouse RL070, run 29 of Session class, 5: instance Mouse RL117, run 26 of Session class, 6: instance Mouse RL117, run 29 of Session class, 7: instance Mouse RL117, run 30 of Session class, 8: instance Mouse RL123, run 22 of Session class, 9: instance Mouse RL116, run 32 of Session class, 10: instance Mouse RL116, run 33 of Session class}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pof' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8a9a85a881da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mpof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_urh_arm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# label arm and urh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0msession_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pof' is not defined"
     ]
    }
   ],
   "source": [
    "## save flu to scratch, restart after this to clear up RAM!\n",
    "pas = PoolAcrossSessions(save_PCA=False, subsample_sessions=False,\n",
    "                         remove_targets=False, remove_toosoon=True)\n",
    "# print(pas.sessions)\n",
    "\n",
    "## Create sessions object from PAS:\n",
    "try:  # ensure sessions doesn't exist yet \n",
    "    sessions\n",
    "    assert type(sessions) is dict\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "sessions = {}\n",
    "int_keys_pas_sessions = pas.sessions.keys()\n",
    "# print(int_keys_pas_sessions)\n",
    "i_s = 0\n",
    "for ses in pas.sessions.values():  # load into sessions dict (in case pas skips an int as key)\n",
    "    ses.signature = f'{ses.mouse}_R{ses.run_number}'\n",
    "    sessions[i_s] = ses\n",
    "    i_s += 1\n",
    "print(sessions)\n",
    "assert len(sessions) == 11\n",
    "pof.label_urh_arm(sessions=sessions)  # label arm and urh\n",
    "\n",
    "session_dict = {}\n",
    "session_idx_dict = {}\n",
    "\n",
    "sessions = {}\n",
    "for i_session in range(11):\n",
    "    F = pas.linear_models[i_session].flu\n",
    "    # with shape (neurons, trials, time)\n",
    "    F_rebinned = np.sum(F.reshape((F.shape[0], F.shape[1], F.shape[2]//3, 3)), axis=-1)\n",
    "    \n",
    "    \n",
    "    s1_idx = np.nonzero(pas.linear_models[i_session].session.s1_bool)[0]\n",
    "    s2_idx = np.nonzero(pas.linear_models[i_session].session.s2_bool)[0]\n",
    "    hit_idx = np.nonzero(pas.linear_models[i_session].session.outcome == 'hit')[0]\n",
    "    miss_idx = np.nonzero(pas.linear_models[i_session].session.outcome == 'miss')[0]\n",
    "    \n",
    "    area = np.zeros(F_rebinned.shape[0], dtype='int')\n",
    "    area[pas.linear_models[i_session].session.s1_bool] = 1\n",
    "    area[pas.linear_models[i_session].session.s2_bool] = 2\n",
    "    trial_type = pas.linear_models[i_session].session.outcome\n",
    "    \n",
    "    data_session = xr.DataArray(F_rebinned, dims = (\"neuron\", \"trial\", \"time\"), \n",
    "                                coords = {\"neuron_num\": (\"neuron\", range(F_rebinned.shape[0])),\n",
    "                                          \"trial_num\": (\"trial\", range(F_rebinned.shape[1])),\n",
    "                                          \"area\": (\"neuron\", area),\n",
    "                                          \"trial_type\": (\"trial\", trial_type)})\n",
    "    data_session = data_session.set_index({'neuron': ('neuron_num','area'), \"trial\": (\"trial_num\", \"trial_type\")})\n",
    "    sessions[str(pas.linear_models[i_session].session)] = data_session\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sessions.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_session.sel(trial_type = \"hit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "def factor_analysis(train_data, test_data=None, n_factors=5):\n",
    "    # data has shape (time, neurons)\n",
    "    transformer = FactorAnalysis(n_components=n_factors)#, random_state=0)\n",
    "    transformer = transformer.fit(train_data)\n",
    "    if test_data is None:\n",
    "        test_data=train_data\n",
    "    return transformer.components_, transformer.transform(test_data), transformer.mean_, transformer.noise_variance_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "squared_off_diag_list = []\n",
    "squared_off_diag_list2 = []\n",
    "for _, session in zip(range(1), sessions.values()):\n",
    "    for n_fact in tqdm(range(0,500,1)):\n",
    "        if n_fact == 0:\n",
    "            L = F = np.array([[0.]]) \n",
    "        else:\n",
    "            arr = session.values.reshape((session.values.shape[0], -1)).transpose()\n",
    "            train_arr = arr[:len(arr)//2]\n",
    "            #test_arr = train_arr\n",
    "            test_arr = arr[len(arr)//2:]\n",
    "            F, L, mean, var = factor_analysis(train_arr,test_arr, n_fact)\n",
    "        res = test_arr - L@F - np.mean(test_arr, axis=0)\n",
    "        cov = np.corrcoef(res.T)\n",
    "        cov2 = np.cov(train_arr.T) - F.T@F\n",
    "        cov2 = cov2/np.sqrt(np.diag(cov2))/np.sqrt(np.diag(cov2))[:,None]\n",
    "        cov[np.arange(len(cov)),np.arange(len(cov))]=0\n",
    "        squared_off_diag = np.sum(cov**2)/(arr.shape[1]**2-arr.shape[1])\n",
    "        squared_off_diag2 = np.sum(cov2**2)/(arr.shape[1]**2-arr.shape[1])\n",
    "        \n",
    "        squared_off_diag_list.append(squared_off_diag)\n",
    "        squared_off_diag_list2.append(squared_off_diag2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(squared_off_diag_list[30:])\n",
    "#plt.plot(squared_off_diag_list2[300:-29])\n",
    "#plt.ylim(0,0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(arr[:1000, 0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist((cov**2).flatten(), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(F[190:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "F.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nvars = 100\n",
    "ntime =1_000\n",
    "ncomp = 10\n",
    "L_test = np.random.normal(size=(nvars,ncomp))\n",
    "mean_test = np.random.normal(size=(nvars))\n",
    "std_test = np.abs(np.random.normal(size=(nvars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_test = mean_test + np.random.normal(size=(ntime, nvars)) @ L_test @ L_test.T * std_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "squared_off_diag_list = []\n",
    "squared_off_diag_list2 = []\n",
    "for n_fact in tqdm(range(0,20,1)):\n",
    "    train_arr = data_test[:len(data_test)//2]\n",
    "    val_arr = data_test[len(data_test)//2:]\n",
    "    if n_fact == 0:\n",
    "        L = F = np.array([[0.]]) \n",
    "    else:\n",
    "        F, L, mean, var = factor_analysis(train_arr,val_arr, n_factors=n_fact)\n",
    "    res = val_arr - L@F - np.mean(val_arr, axis=0)\n",
    "    cov = np.corrcoef(res.T)\n",
    "    cov2 = np.cov(train_arr.T) - F.T@F\n",
    "    cov2 = cov2/np.sqrt(np.diag(cov2))/np.sqrt(np.diag(cov2))[:,None]\n",
    "    cov[np.arange(len(cov)),np.arange(len(cov))]=0\n",
    "    squared_off_diag = np.sum(cov**2)/(arr.shape[1]**2-arr.shape[1])\n",
    "    squared_off_diag2 = np.sum(cov2**2)/(arr.shape[1]**2-arr.shape[1])\n",
    "\n",
    "    squared_off_diag_list.append(squared_off_diag)\n",
    "    squared_off_diag_list2.append(squared_off_diag2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(squared_off_diag_list[-20:])\n",
    "plt.plot(squared_off_diag_list2[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_HornParallelAnalysis(data_test, K=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_HornParallelAnalysis(arr, K=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.ylim(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from factor_analyzer import FactorAnalyzer\n",
    "\n",
    "\n",
    "def _HornParallelAnalysis(data, K=10, printEigenvalues=False):\n",
    "    ################\n",
    "    # Create a random matrix to match the dataset\n",
    "    ################\n",
    "    n, m = data.shape\n",
    "    # Set the factor analysis parameters\n",
    "    fa = FactorAnalyzer(n_factors=1, method='minres', rotation=None, use_smc=True)\n",
    "    # Create arrays to store the values\n",
    "    sumComponentEigens = np.empty(m)\n",
    "    sumFactorEigens = np.empty(m)\n",
    "    # Run the fit 'K' times over a random matrix\n",
    "    for runNum in tqdm(range(0, K)):\n",
    "        fa.fit(np.random.normal(size=(n, m)))\n",
    "        sumComponentEigens = sumComponentEigens + fa.get_eigenvalues()[0]\n",
    "        sumFactorEigens = sumFactorEigens + fa.get_eigenvalues()[1]\n",
    "    # Average over the number of runs\n",
    "    avgComponentEigens = sumComponentEigens / K\n",
    "    avgFactorEigens = sumFactorEigens / K\n",
    "\n",
    "    ################\n",
    "    # Get the eigenvalues for the fit on supplied data\n",
    "    ################\n",
    "    fa.fit(data)\n",
    "    dataEv = fa.get_eigenvalues()\n",
    "    # Set up a scree plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    ################\n",
    "    ### Print results\n",
    "    ################\n",
    "    if printEigenvalues:\n",
    "        print('Principal component eigenvalues for random matrix:\\n', avgComponentEigens)\n",
    "        print('Factor eigenvalues for random matrix:\\n', avgFactorEigens)\n",
    "        print('Principal component eigenvalues for data:\\n', dataEv[0])\n",
    "        print('Factor eigenvalues for data:\\n', dataEv[1])\n",
    "    # Find the suggested stopping points\n",
    "    suggestedFactors = sum((dataEv[1] - avgFactorEigens) > 0)\n",
    "    suggestedComponents = sum((dataEv[0] - avgComponentEigens) > 0)\n",
    "    print('Parallel analysis suggests that the number of factors = ', suggestedFactors , ' and the number of components = ', suggestedComponents)\n",
    "\n",
    "\n",
    "    ################\n",
    "    ### Plot the eigenvalues against the number of variables\n",
    "    ################\n",
    "    # Line for eigenvalue 1\n",
    "    plt.plot([0, m+1], [1, 1], 'k--', alpha=0.3)\n",
    "    # For the random data - Components\n",
    "    plt.plot(range(1, m+1), avgComponentEigens, 'b', label='PC - random', alpha=0.4)\n",
    "    # For the Data - Components\n",
    "    plt.scatter(range(1, m+1), dataEv[0], c='b', marker='o')\n",
    "    plt.plot(range(1, m+1), dataEv[0], 'b', label='PC - data')\n",
    "    # For the random data - Factors\n",
    "    plt.plot(range(1, m+1), avgFactorEigens, 'g', label='FA - random', alpha=0.4)\n",
    "    # For the Data - Factors\n",
    "    plt.scatter(range(1, m+1), dataEv[1], c='g', marker='o')\n",
    "    plt.plot(range(1, m+1), dataEv[1], 'g', label='FA - data')\n",
    "    plt.title('Parallel Analysis Scree Plots', {'fontsize': 20})\n",
    "    plt.xlabel('Factors/Components', {'fontsize': 15})\n",
    "    plt.xticks(ticks=range(1, m+1), labels=range(1, m+1))\n",
    "    plt.ylabel('Eigenvalue', {'fontsize': 15})\n",
    "    plt.legend()\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = arr\n",
    "K = 1\n",
    "################\n",
    "# Create a random matrix to match the dataset\n",
    "################\n",
    "n, m = data.shape\n",
    "# Set the factor analysis parameters\n",
    "fa = FactorAnalyzer(n_factors=1, method='minres', rotation=None, use_smc=True)\n",
    "# Create arrays to store the values\n",
    "sumComponentEigens = np.empty(m)\n",
    "sumFactorEigens = np.empty(m)\n",
    "# Run the fit 'K' times over a random matrix\n",
    "for runNum in tqdm(range(0, K)):\n",
    "    fa.fit(np.random.normal(size=(n, m)))\n",
    "    sumComponentEigens = sumComponentEigens + fa.get_eigenvalues()[0]\n",
    "    sumFactorEigens = sumFactorEigens + fa.get_eigenvalues()[1]\n",
    "# Average over the number of runs\n",
    "avgComponentEigens = sumComponentEigens / K\n",
    "avgFactorEigens = sumFactorEigens / K\n",
    "\n",
    "################\n",
    "# Get the eigenvalues for the fit on supplied data\n",
    "################\n",
    "fa.fit(data)\n",
    "dataEv = fa.get_eigenvalues()\n",
    "# Set up a scree plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "################\n",
    "### Print results\n",
    "################\n",
    "if printEigenvalues:\n",
    "    print('Principal component eigenvalues for random matrix:\\n', avgComponentEigens)\n",
    "    print('Factor eigenvalues for random matrix:\\n', avgFactorEigens)\n",
    "    print('Principal component eigenvalues for data:\\n', dataEv[0])\n",
    "    print('Factor eigenvalues for data:\\n', dataEv[1])\n",
    "# Find the suggested stopping points\n",
    "suggestedFactors = sum((dataEv[1] - avgFactorEigens) > 0)\n",
    "suggestedComponents = sum((dataEv[0] - avgComponentEigens) > 0)\n",
    "print('Parallel analysis suggests that the number of factors = ', suggestedFactors , ' and the number of components = ', suggestedComponents)\n",
    "\n",
    "\n",
    "################\n",
    "### Plot the eigenvalues against the number of variables\n",
    "################\n",
    "# Line for eigenvalue 1\n",
    "plt.plot([0, m+1], [1, 1], 'k--', alpha=0.3)\n",
    "# For the random data - Components\n",
    "plt.plot(range(1, m+1), avgComponentEigens, 'b', label='PC - random', alpha=0.4)\n",
    "# For the Data - Components\n",
    "plt.scatter(range(1, m+1), dataEv[0], c='b', marker='o')\n",
    "plt.plot(range(1, m+1), dataEv[0], 'b', label='PC - data')\n",
    "# For the random data - Factors\n",
    "plt.plot(range(1, m+1), avgFactorEigens, 'g', label='FA - random', alpha=0.4)\n",
    "# For the Data - Factors\n",
    "plt.scatter(range(1, m+1), dataEv[1], c='g', marker='o')\n",
    "plt.plot(range(1, m+1), dataEv[1], 'g', label='FA - data')\n",
    "plt.title('Parallel Analysis Scree Plots', {'fontsize': 20})\n",
    "plt.xlabel('Factors/Components', {'fontsize': 15})\n",
    "plt.xticks(ticks=range(1, m+1), labels=range(1, m+1))\n",
    "plt.ylabel('Eigenvalue', {'fontsize': 15})\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggestedFactors = sum((dataEv[1] - avgFactorEigens) > 0)\n",
    "suggestedComponents = sum((dataEv[0] - avgComponentEigens) > 0)\n",
    "print('Parallel analysis suggests that the number of factors = ', suggestedFactors , ' and the number of components = ', suggestedComponents)\n",
    "\n",
    "\n",
    "################\n",
    "### Plot the eigenvalues against the number of variables\n",
    "################\n",
    "# Line for eigenvalue 1\n",
    "plt.plot([0, m+1], [1, 1], 'k--', alpha=0.3)\n",
    "# For the random data - Components\n",
    "plt.plot(range(1, m+1), avgComponentEigens, 'b', label='PC - random', alpha=0.4)\n",
    "# For the Data - Components\n",
    "plt.scatter(range(1, m+1), dataEv[0], c='b', marker='o')\n",
    "plt.plot(range(1, m+1), dataEv[0], 'b', label='PC - data')\n",
    "# For the random data - Factors\n",
    "plt.plot(range(1, m+1), avgFactorEigens, 'g', label='FA - random', alpha=0.4)\n",
    "# For the Data - Factors\n",
    "plt.scatter(range(1, m+1), dataEv[1], c='g', marker='o')\n",
    "plt.plot(range(1, m+1), dataEv[1], 'g', label='FA - data')\n",
    "plt.title('Parallel Analysis Scree Plots', {'fontsize': 20})\n",
    "plt.xlabel('Factors/Components', {'fontsize': 15})\n",
    "plt.xticks(ticks=range(1, m+1), labels=range(1, m+1))\n",
    "plt.ylabel('Eigenvalue', {'fontsize': 15})\n",
    "plt.ylim(0,10)\n",
    "plt.xlim(0,50)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.ylim(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for _, session in zip(range(11), sessions.values()):\n",
    "    eigenvalues = []\n",
    "    n_fact = 50\n",
    "    if n_fact == 0:\n",
    "        L = F = np.array([[0.]]) \n",
    "    else:\n",
    "        arr = session.values.reshape((session.values.shape[0], -1)).transpose()\n",
    "        #train_arr = arr[:len(arr)//2]\n",
    "        #test_arr = train_arr\n",
    "        #test_arr = arr[len(arr)//2:]\n",
    "        F, L, mean, var = factor_analysis(arr, n_factors = n_fact)\n",
    "        cov2 = F.T@F\n",
    "        cov2 = cov2/np.sqrt(np.diag(cov2))/np.sqrt(np.diag(cov2))[:,None]\n",
    "        eigenvalues = np.linalg.eigh(cov2)[0][::-1]\n",
    "    plt.semilogy(eigenvalues)\n",
    "    plt.ylim(1,200)\n",
    "    plt.xlim(0,50)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for _, session in zip(range(11), sessions.values()):\n",
    "    eigenvalues = []\n",
    "    n_fact = 50\n",
    "    if n_fact == 0:\n",
    "        L = F = np.array([[0.]]) \n",
    "    else:\n",
    "        arr = session.values.reshape((session.values.shape[0], -1)).transpose()\n",
    "        #train_arr = arr[:len(arr)//2]\n",
    "        #test_arr = train_arr\n",
    "        #test_arr = arr[len(arr)//2:]\n",
    "        F, L, mean, var = factor_analysis(arr, n_factors = n_fact)\n",
    "        cov2 = F.T@F\n",
    "        #cov2 = cov2/np.sqrt(np.diag(cov2))/np.sqrt(np.diag(cov2))[:,None]\n",
    "        eigenvalues = np.linalg.eigh(cov2)[0][::-1]\n",
    "    plt.semilogy(eigenvalues)\n",
    "    plt.ylim(1,200)\n",
    "    plt.xlim(0,50)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
